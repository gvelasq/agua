---
title: "Tuning with agua"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tuning with agua}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Hyper-parameter tuning with agua 

agua sets up the infrastructure for the `tune` package to enable optimization of h2o models. Similar to other models, we label the hyperparameter with the `tune()` placeholder and feed them into `tune_*()` functions such as `tune_grid()` and `tune_bayes()`. We will use the tuning example from [Introduction to tune](https://tune.tidymodels.org/articles/tune.html) with the Ames housing data. 

```{r, message = FALSE}
library(tidymodels)
library(agua)
library(ggplot2)
theme_set(theme_bw())
doParallel::registerDoParallel()
h2o_start()
data(ames)

set.seed(4595)
data_split <- ames %>%
  mutate(Sale_Price = log10(Sale_Price)) %>%
  initial_split(strata = Sale_Price)
ames_train <- training(data_split)
ames_test  <- testing(data_split)
cv_splits <- vfold_cv(ames_train, v = 10, strata = Sale_Price)

ames_rec <- 
  recipe(Sale_Price ~ Gr_Liv_Area + Longitude + Latitude, data = ames_train) %>% 
  step_log(Gr_Liv_Area, base = 10) %>% 
  step_ns(Longitude, deg_free = tune("long df")) %>% 
  step_ns(Latitude,  deg_free = tune("lat df"))

lm_mod <- linear_reg(penalty = tune()) %>% 
  set_engine("h2o")

lm_wflow <- workflow() %>% 
  add_model(lm_mod) %>%
  add_recipe(ames_rec)

grid <- lm_wflow %>%
  extract_parameter_set_dials() %>% 
  grid_regular(levels = 5)

ames_res <- tune_grid(
  lm_wflow, 
  resamples = cv_splits, 
  grid = grid, 
  control = control_grid(save_pred = TRUE)
)

ames_res 
```

The syntax is the same, we provide a workflow and the grid of hyper-parameters, then `tune_grid()` returns cross validation 
performances for every parameterization on the resamples. The only difference is calling `h2o_start()` 
beforehand to use the `'h2o'` engine. Other functions in `tune` for working with tuning results such as `collect_metrics()`, `collect_predictions()` and `autoplot()` will also recognize `ames_res` and work as expected. 

```{r}
collect_metrics(ames_res, summarize = FALSE)
```

```{r}
autoplot(ames_res, metric = "rmse")
```



Currently, there are a couple of limitations when tuning h2o models with agua:

- Only regular grid is supported, as created by `expand.grid()`, `dials::grid_regular()`,
or `tidyr::crossing()`. We also need to set `grid` in `tune_*()` functions explicitly to prevent the default grid generation. 

- Parallelization on the R side is over resamples, i.e., `control = control_grid(parallel_over = 'resamples')`. We can't set `parallel_over = 'everything'`
for an inner parallel loop of tuning parameters. Yet the h2o server by can build models 
in parallel with adaptive parallelism. 

## Tuning internals 

For users interested to understand the limitations and performance characteristics of tuning h2o models with agua, it is helpful to know some inner workings of h2o. agua uses 
the `h2o::h2o.grid()` function for tuning model parameters, which accepts a list of hyper-parameters, construct a regular grid, and search for the optimal 
combination for a given dataset.

In the above example, we have three tuning parameters of two types: 

```{r}
extract_parameter_set_dials(lm_wflow)
```

* tuning parameters in the model: `penalty`.

* tuning parameters in the preprocessor: `long df` and `lat df`. 

Since `h2o.grid` only optimizes model parameters, agua or the h2o server does not interfere with tuning preprocessors. Possible values `long df` and `lat df` in the regular grid `grid` will be iterated as usual on the R side, once a certain combination of them is chosen, agua engineered all relevant features, then passes the data and model definitions to the h2o server for the rest of model tuning. Also, `h2o.grid()` only supports regular tuning grids, therefore we can't use grid of other types. 

If you have a parallel backend registered, models per resample will be optimized and evaluated 
in parallel. The h2o server would still require R to pass in the complete set of parameters for one resample. For this reason, we can't have `parallel_over = 'everything'` on the R side. 

**TODO**: how to use `parallelism` in `h2o::h2o.grid`

Regarding the performance of model evaluation, `h2o.grid()` supports passing in a validation
frame but does not return predictions on that data. In order to compute metrics on the holdout sample, we have to retrieve the model,
convert validation data into the desired format, predict on it, and convert the results back to data frames. In the future we hope it can return the predictions directly thus eliminating excessive data conversions. 
