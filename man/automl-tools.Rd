% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/auto-ml.R
\name{rank_results_automl}
\alias{rank_results_automl}
\alias{rank_results_automl.default}
\alias{rank_results_automl.model_fit}
\alias{rank_results_automl.H2OAutoML}
\alias{tidy._H2OAutoML}
\alias{get_leaderboard}
\alias{member_weights}
\alias{extract_fit_parsnip._H2OAutoML}
\title{Tools for working with H2O AutoML results}
\usage{
rank_results_automl(object, ...)

\method{rank_results_automl}{default}(object, ...)

\method{rank_results_automl}{model_fit}(object, n = NULL, id = NULL, ...)

\method{rank_results_automl}{H2OAutoML}(object, n = NULL, id = NULL, summarize = TRUE, ...)

\method{tidy}{`_H2OAutoML`}(object, n = NULL, id = NULL, keep_model = TRUE, ...)

get_leaderboard(object, n = NULL, id = NULL)

member_weights(object, ...)

\method{extract_fit_parsnip}{`_H2OAutoML`}(object, id = NULL, ...)
}
\arguments{
\item{object}{A fitted \code{auto_ml()} model.}

\item{...}{Not used.}

\item{n}{The number of models to extract from \code{auto_ml()} results,
default to all.}

\item{id}{A character vector of model ids to retrieve.}

\item{summarize}{A logical value for should metrics be summarized over
resamples. Rankings are always based on average performance even if
\code{summarize} is \code{FALSE}.}

\item{keep_model}{A logical value for if the actual model object
should be retrieved from the server. Defaults to \code{TRUE}.}
}
\value{
A \code{\link[tibble:tibble]{tibble::tibble()}}.
}
\description{
\code{rank_results_automl()} ranks average cross validation performances of different
candidate models and algorithms on each metric.

\code{tidy()} returns a tibble with average performance for each candidate model.
When \code{keep_model} is \code{TRUE}, \code{tidy()} adds a list column where each
component is a "fake" parsnip \code{model_fit} object constructed
from the h2o model. These objects are meant to be used for prediction only,
i.e., \code{predict(object, new_data = data)}, and should not be used as a
regular parsnip model.

\code{member_weights()} computes variable importance for all stacked ensemble
models, i.e., the relative importance of base models in the meta-learner.
This is typically the coefficient magnitude in the second-level GLM model.

\code{extract_fit_parsnip()} is a s3 method to extract candidate model from
\code{auto_ml()} results. When \code{id} is null, it returns the leader model.
}
\details{
Algorithms in h2o's automatic machine learning include xgboost,
gradient boosting (\code{"GBM"}), random forest and variants (\code{"DRF"}, \code{"XRT"}),
generalized linear model (\code{"GLM"}), and neural network (\code{"deeplearning"}).
See the details section in \code{\link[h2o:h2o.automl]{h2o::h2o.automl()}} for more information.
}
\examples{
if (h2o_running()) {
  mod <- auto_ml() \%>\%
    set_engine("h2o", max_runtime_secs = 10) \%>\%
    set_mode("regression") \%>\%
    fit(mpg ~ ., data = mtcars)

  rank_results_automl(mod)
  tidy(mod)
  imp_stacking(mod)
}

}
